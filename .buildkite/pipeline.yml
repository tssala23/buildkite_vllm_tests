steps:
  - label: Entrypoints Test
    agents:
        queue: moc-cpu
    soft_fail: false
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 1
        - exit_status: -10  # Agent was lost
          limit: 1
    commands:
      - cd /vllm-workspace/tests
      - pytest -v -s entrypoints/llm --ignore=entrypoints/llm/test_lazy_outlines.py --ignore=entrypoints/llm/test_generate.py --ignore=entrypoints/llm/test_generate_multiple_loras.py --ignore=entrypoints/llm/test_guided_generate.py --ignore=entrypoints/llm/test_collective_rpc.py
      - pytest -v -s entrypoints/llm/test_lazy_outlines.py # it needs a clean process
      - pytest -v -s entrypoints/llm/test_generate.py # it needs a clean process
      - pytest -v -s entrypoints/llm/test_generate_multiple_loras.py # it needs a clean process
      - pytest -v -s entrypoints/llm/test_guided_generate.py # it needs a clean process
      - pytest -v -s entrypoints/openai --ignore=entrypoints/openai/test_oot_registration.py
      - pytest -v -s entrypoints/test_chat_utils.py
      - pytest -v -s entrypoints/offline_mode # Needs to avoid interference with other tests
    plugins:
      - kubernetes:
          podSpec:
            priorityClassName: ci
            containers:
            - image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:4cfd785c7803bcbf65fabbd37a5ff7d5b8bb1502
              resources:
                requests:
                nvidia.com/gpu: 2
                limits:
                  nvidia.com/gpu: 2
            tolerations:
            - key: "nvidia.com/gpu.product"
              operator: "Equal"
              value: "NVIDIA-A100-SXM4-40GB"
              effect: "NoSchedule"
